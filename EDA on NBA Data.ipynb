{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "793b62d9",
   "metadata": {},
   "source": [
    "<h1>NBA correlation problem</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f6af56-1e3a-4954-aebf-20c34b2be8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nba_correlation(): \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import scipy.stats as stats\n",
    "    import re\n",
    "    \n",
    "    #Importing our data\n",
    "    nba_df=pd.read_csv(\"assets/nba.csv\")\n",
    "    cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "    cities= cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "    cities.head()\n",
    "\n",
    "    #We will now perform a basic data clean-up process\n",
    "\n",
    "    def clean_up_cities_rules(cities, sport): \n",
    "        #We rename the columns to easier names to work with\n",
    "        cities.rename(columns = {\"Population (2016 est.)[8]\":\"Population\", \"Metropolitan area\":\"City\"}, inplace = True)\n",
    "        #We keep only the relevant to the sport team\n",
    "        cities = cities[[\"City\",\"Population\",sport]]\n",
    "        #We replace the -- with NaN cause it's easier to handle\n",
    "        cities.loc[:,sport] = cities.loc[:,sport].replace(\"—\",np.nan)\n",
    "        cities = cities.dropna()\n",
    "        #We want to replace everything in [] with \"\"\n",
    "        cities.loc[:,sport] = cities.loc[:,sport].replace(\"\\[.*\\]\",\"\",regex = True)\n",
    "        #Anything that is empty at the sports column will be the ones that don't have this sport on the city\n",
    "        cities.loc[:,sport] = cities.loc[:,sport].replace(\"\",np.nan)\n",
    "        cities = cities.dropna()\n",
    "        return cities\n",
    "\n",
    "    metro_rules_NBA = clean_up_cities_rules(cities,\"NBA\")\n",
    "\n",
    "    #Now let's do a similar clean-up process for the NBA sheet\n",
    "    #We will do it by hand first and maybe we'll write a function later \n",
    "    nba_stats = pd.read_csv(\"assets/nba.csv\")\n",
    "\n",
    "    #We see we have to clean the team names\n",
    "    #We essentially have to clean everything after the * \n",
    "    def clean_nba_name(row): \n",
    "        row = re.sub(r'\\*.*', \"\", row).strip() #Cleans everything after an asterisk\n",
    "        row = re.sub(r\"\\(.*\",\"\",row).strip() #Cleans everything after a parenthesis\n",
    "        return row\n",
    "\n",
    "    nba_stats.loc[:,\"team\"] = nba_stats.loc[:,\"team\"].apply(lambda x: clean_nba_name(x))\n",
    "\n",
    "    #We want to keep only 2018 data \n",
    "    mask2018 = nba_stats[\"year\"] == 2018\n",
    "    nba_stats = nba_stats[mask2018]\n",
    "\n",
    "    \n",
    "    #Okay now we have the 30 teams of the 2018 NBA \n",
    "    #From this table we only want the teams and their W/L\n",
    "    nba_stats = nba_stats.loc[:,[\"team\",\"W/L%\"]]\n",
    "    #We also want to make our city column\n",
    "    nba_stats[\"City\"] = np.nan\n",
    "\n",
    "    #Let's do the same procedure\n",
    "    #This is the function that will find the problematic team names \n",
    "    easy_named_teams = []\n",
    "    problematic_names = []\n",
    "    #This function can check if the city of the team in the nhl_stats is found in \n",
    "    #our cities column\n",
    "            \n",
    "            \n",
    "    def assign_city(tname): \n",
    "        if tname.split()[0] in str(metro_rules_NBA[\"City\"].unique()):\n",
    "            easy_named_teams.append(tname)\n",
    "        else: \n",
    "            problematic_names.append(tname)\n",
    "    \n",
    "    nba_stats[\"team\"].apply(lambda x: assign_city(x))\n",
    "\n",
    "    #These are our problematic ones \n",
    "    #Let's create a dictionary and quickly match them \n",
    "    problematic_mapping = {\n",
    "    \"Brooklyn Nets\": \"New York City\",\n",
    "    \"Golden State Warriors\": \"San Francisco Bay Area\",\n",
    "    \"Utah Jazz\": \"Salt Lake City\",\n",
    "    \"Minnesota Timberwolves\": \"Minneapolis–Saint Paul\",\n",
    "    }\n",
    "\n",
    "    def team_rename(row, dictionary): \n",
    "        team_name = row[\"team\"] #Get the team name from the team column \n",
    "        if team_name in dictionary.keys(): #If it's in that mapping add the value in the City col\n",
    "            row[\"City\"] = dictionary[team_name]\n",
    "        return row\n",
    "\n",
    "    #We will now apply this with the dictionary = problematic_mapping \n",
    "    nba_stats = nba_stats.apply(team_rename, axis = 1, dictionary = problematic_mapping)\n",
    "\n",
    "    #Beautiful let's now fix up our other teams as well. \n",
    "    def find_city_by_team(tname):\n",
    "        result = metro_rules_NBA[metro_rules_NBA[\"City\"].str.startswith(tname.split()[0])]\n",
    "        #Get the City columns that start with the first word of my tname\n",
    "        return result[\"City\"].iloc[0]\n",
    "    \n",
    "    easy_named_teams_dict = {}\n",
    "    \n",
    "    for team in easy_named_teams: \n",
    "        try: easy_named_teams_dict[team] = find_city_by_team(team)\n",
    "        except: continue\n",
    "\n",
    "    nba_stats = nba_stats.apply(team_rename, axis = 1, dictionary = easy_named_teams_dict)\n",
    "    #So our easy teams our now done as well\n",
    "    #There is only one problem with this - it maps depending on the first word so let's just fix those weird ones\n",
    "    #Correcting San Antonio and New Orleans \n",
    "    nba_stats.loc[20,\"City\"] = \"New Orleans\"\n",
    "    nba_stats.loc[21,\"City\"] = \"San Antonio\"\n",
    "\n",
    "    nba_stats[\"W/L%\"] = nba_stats[\"W/L%\"].astype(float)\n",
    "    mean_wl = nba_stats[\"W/L%\"].groupby(nba_stats[\"City\"]).mean()\n",
    "    final = pd.merge(metro_rules_NBA, mean_wl, how = \"inner\", on = \"City\")\n",
    "\n",
    "    correlation = stats.pearsonr(final[\"Population\"].astype(float), final[\"W/L%\"].astype(float))\n",
    "\n",
    "    return correlation[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9fb5d80-46da-4c7a-a181-32c4a2a24228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.17636350642182938"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2936873-f34a-4b1a-bc0c-275d5844aae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
